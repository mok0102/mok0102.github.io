---
layout: post
title:  "SMILE-NEXT: An Enhanced Multimodal Dataset and Model for Laughter Understanding"
date:   2024-10-15 22:21:59 +00:00
image: /images/smilenext.png
categories: ongoing
author: "Lee JungMok"
venue: "ongoing"
authors: "<strong>Lee JungMok</strong>, Kim Sung-Bin, Lee Hyun, Tae-Hyun Oh"
subtitle: "Enhanced Multimodal Laughter Dataset and Laugh-Expert Model"
arxiv: https://arxiv.org/abs/2509.25946
code: https://github.com/kaist-ami
website: https://github.com/kaist-ami
---

We introduce the SMILE-NEXT, a comprehensive corpus combining audio, visual, and textual cues for laughter understanding across diverse contexts. We propose Laugh Expert MOE architecture, a lightweight yet expressive model architecture to efficiently model laughter perception.